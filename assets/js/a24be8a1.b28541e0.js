"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[813],{4842:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"chapters/appendices/index","title":"index","description":"---","source":"@site/docs/chapters/appendices/index.mdx","sourceDirName":"chapters/appendices","slug":"/chapters/appendices/","permalink":"/physical-ai-book/docs/chapters/appendices/","draft":false,"unlisted":false,"editUrl":"https://github.com/zohaibfaiz0/physical-ai-book/docs/chapters/appendices/index.mdx","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"capstone-full-autonomous-humanoid","permalink":"/physical-ai-book/docs/chapters/week-13-conversational-robotics/capstone-full-autonomous-humanoid"}}');var o=i(4848),r=i(8453),t=i(4588);const a={},l=void 0,c={},d=[{value:"title: &quot;Appendices&quot;\ndescription: &quot;Supplementary materials, hardware recommendations, and additional resources for Physical AI and Humanoid Robotics&quot;",id:"title-appendicesdescription-supplementary-materials-hardware-recommendations-and-additional-resources-for-physical-ai-and-humanoid-robotics",level:2},{value:"Hardware Recommendations",id:"hardware-recommendations",level:2},{value:"Assessment Overview",id:"assessment-overview",level:2},{value:"Practical Assessments",id:"practical-assessments",level:3},{value:"Technical Evaluations",id:"technical-evaluations",level:3},{value:"Project-Based Assessments",id:"project-based-assessments",level:3},{value:"Glossary",id:"glossary",level:2},{value:"Further Reading",id:"further-reading",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function h(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"title-appendicesdescription-supplementary-materials-hardware-recommendations-and-additional-resources-for-physical-ai-and-humanoid-robotics",children:'title: "Appendices"\ndescription: "Supplementary materials, hardware recommendations, and additional resources for Physical AI and Humanoid Robotics"'}),"\n",(0,o.jsx)(n.h1,{id:"appendices",children:"Appendices"}),"\n",(0,o.jsx)(t.A,{}),"\n",(0,o.jsx)(n.p,{children:"This section contains supplementary materials, technical references, and additional resources to support your journey through Physical AI and Humanoid Robotics development. These appendices provide practical guidance for hardware selection, assessment criteria, terminology, and further learning opportunities."}),"\n",(0,o.jsx)(n.h2,{id:"hardware-recommendations",children:"Hardware Recommendations"}),"\n",(0,o.jsx)(n.p,{children:"The following table provides recommendations for hardware components suitable for different levels of Physical AI and Humanoid Robotics projects:"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Component"}),(0,o.jsx)(n.th,{children:"Model"}),(0,o.jsx)(n.th,{children:"Specifications"}),(0,o.jsx)(n.th,{children:"Use Case"}),(0,o.jsx)(n.th,{children:"Price Range"}),(0,o.jsx)(n.th,{children:"Notes"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"AI Computer"}),(0,o.jsx)(n.td,{children:"NVIDIA Jetson Orin Nano"}),(0,o.jsx)(n.td,{children:"1024-core NVIDIA Ampere GPU, 4-core ARM CPU, 4GB LPDDR5"}),(0,o.jsx)(n.td,{children:"Small-scale robotics, vision processing"}),(0,o.jsx)(n.td,{children:"$400-500"}),(0,o.jsx)(n.td,{children:"Excellent power efficiency for mobile robots"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Depth Camera"}),(0,o.jsx)(n.td,{children:"Intel RealSense D455"}),(0,o.jsx)(n.td,{children:"1280\xd7720 depth resolution, 94\xb0 HFOV, RGB camera"}),(0,o.jsx)(n.td,{children:"3D perception, mapping, object detection"}),(0,o.jsx)(n.td,{children:"$200-250"}),(0,o.jsx)(n.td,{children:"Good for indoor applications"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"IMU Sensor"}),(0,o.jsx)(n.td,{children:"Bosch BNO055"}),(0,o.jsx)(n.td,{children:"9-axis absolute orientation sensor, integrated sensor fusion"}),(0,o.jsx)(n.td,{children:"Robot stabilization, orientation tracking"}),(0,o.jsx)(n.td,{children:"$30-40"}),(0,o.jsx)(n.td,{children:"Easy I2C/SPI integration"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Motor Controller"}),(0,o.jsx)(n.td,{children:"Pololu Jrk 21v3"}),(0,o.jsx)(n.td,{children:"5.5V to 21V, 23A max current, USB/serial control"}),(0,o.jsx)(n.td,{children:"Precise motor control, feedback systems"}),(0,o.jsx)(n.td,{children:"$50-60"}),(0,o.jsx)(n.td,{children:"Good for servo and DC motor control"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Actuators"}),(0,o.jsx)(n.td,{children:"Dynamixel X-Series"}),(0,o.jsx)(n.td,{children:"Various models (XL430, XM430, etc.), position/torque control"}),(0,o.jsx)(n.td,{children:"Robotic arms, humanoid joints"}),(0,o.jsx)(n.td,{children:"$100-300/unit"}),(0,o.jsx)(n.td,{children:"High precision, daisy-chainable"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"LIDAR"}),(0,o.jsx)(n.td,{children:"Slamtec RPLidar A1M8"}),(0,o.jsx)(n.td,{children:"360\xb0 scanning, 6m range, 10Hz update rate"}),(0,o.jsx)(n.td,{children:"Mapping, navigation, obstacle detection"}),(0,o.jsx)(n.td,{children:"$300-400"}),(0,o.jsx)(n.td,{children:"Good for indoor SLAM applications"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Power Management"}),(0,o.jsx)(n.td,{children:"Adafruit PowerBoost 1000C"}),(0,o.jsx)(n.td,{children:"5V/1000mA boost converter, LiPo charging"}),(0,o.jsx)(n.td,{children:"Battery management, power regulation"}),(0,o.jsx)(n.td,{children:"$20-25"}),(0,o.jsx)(n.td,{children:"Essential for mobile robot power systems"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Communication"}),(0,o.jsx)(n.td,{children:"XBee 3 Cellular"}),(0,o.jsx)(n.td,{children:"LTE-M/NB-IoT, 50km range, low power"}),(0,o.jsx)(n.td,{children:"Long-range communication, remote control"}),(0,o.jsx)(n.td,{children:"$100-150"}),(0,o.jsx)(n.td,{children:"For remote robot communication"})]})]})]}),"\n",(0,o.jsx)(n.h2,{id:"assessment-overview",children:"Assessment Overview"}),"\n",(0,o.jsx)(n.p,{children:"This course employs multiple assessment strategies to ensure comprehensive understanding of Physical AI and Humanoid Robotics concepts:"}),"\n",(0,o.jsx)(n.h3,{id:"practical-assessments",children:"Practical Assessments"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation Challenges"}),": Complete complex tasks in Gazebo and Isaac Sim environments"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Hardware Integration"}),": Successfully integrate sensors and actuators with robotic platforms"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Navigation Tasks"}),": Implement path planning and obstacle avoidance in real environments"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Manipulation Challenges"}),": Execute precise grasping and manipulation tasks"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"technical-evaluations",children:"Technical Evaluations"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Code Quality"}),": Assessment of implementation following ROS 2 best practices"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"System Design"}),": Evaluation of architectural decisions and system integration"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Performance Metrics"}),": Analysis of computational efficiency, accuracy, and reliability"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Documentation"}),": Quality of technical documentation and user guides"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"project-based-assessments",children:"Project-Based Assessments"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Mid-term Project"}),": Implement a complete robotic behavior using VLA models"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Final Project"}),": Develop an autonomous humanoid task execution system"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Peer Review"}),": Evaluate and provide feedback on fellow students' implementations"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"glossary",children:"Glossary"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Affordance"}),": The property of an object that defines how it can be used or interacted with in a specific environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Embodied AI"}),": Artificial intelligence systems that exist and operate in physical environments, interacting with the real world through sensors and actuators."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Forward Kinematics"}),": The process of determining the position and orientation of a robot's end-effector based on joint angles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Inverse Kinematics"}),": The process of determining the joint angles required to achieve a desired end-effector position and orientation."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Locomotion"}),": The ability of a robot to move from one location to another, typically referring to walking, rolling, or crawling."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Manipulation"}),": The ability of a robot to interact with objects in its environment, typically through grasping, moving, or modifying objects."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Perception Pipeline"}),": The sequence of processing steps that convert raw sensor data into meaningful information about the environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Reactive Control"}),": A control strategy that responds directly to sensor inputs without maintaining an internal model of the world."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"}),": The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Teleoperation"}),": Remote control of a robot by a human operator, often with haptic feedback."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"VLA (Vision-Language-Action) Models"}),": AI models that integrate visual perception, language understanding, and physical action execution in a unified framework."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Whole-Body Control"}),": A control approach that considers the entire robot as a single system, optimizing all joint movements simultaneously for optimal performance."]}),"\n",(0,o.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://link.springer.com/book/10.1007/978-3-319-32552-1",children:"Siciliano, B., & Khatib, O. (Eds.). (2016). Springer Handbook of Robotics. Springer."})," - Comprehensive reference on robotics fundamentals and applications."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://mitpress.mit.edu/books/probabilistic-robotics",children:"Thrun, S., Burgard, W., & Fox, D. (2005). Probabilistic Robotics. MIT Press."})," - Essential text on uncertainty in robotics and probabilistic approaches to robot perception and control."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://www.deeplearningbook.org/",children:"Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press."})," - Foundational text on deep learning principles applicable to embodied AI systems."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://www.crcpress.com/A-Mathematical-Introduction-to-Robotic-Manipulation/Murray-Li-Sastry/p/book/9780849348629",children:"Murray, R. M., Li, Z., & Sastry, S. S. (1994). A Mathematical Introduction to Robotic Manipulation. CRC Press."})," - Mathematical foundations for robotic manipulation and control."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://onlinelibrary.wiley.com/doi/full/10.1002/rob.21630",children:"Hutter, M., Gehring, C., & Siegwart, R. (2016). Reactive Walking of a Humanoid Robot Over Discrete Obstacles. Journal of Field Robotics."})," - Advanced locomotion techniques for humanoid robots."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://www.sciencedirect.com/science/article/pii/000437029190053M",children:"Brooks, R. A. (1991). Intelligence without representation. Artificial Intelligence."})," - Foundational paper on embodied cognition and situated robotics."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://arxiv.org/abs/2302.08540",children:"Driess, D., et al. (2023). Palm-e: An embodied generative model. arXiv preprint."})," - Latest research on embodied language models for robotics."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://arxiv.org/abs/2203.06173",children:"OpenAI et al. (2022). Robotic Skill Learning from Language Guidance. arXiv preprint."})," - State-of-the-art approaches to language-guided robotic learning."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://aihabitat.org/challenge/",children:"Embodied AI Challenge Series."})," - Annual competition and resources for embodied AI research and development."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://www.ieee-ras.org/",children:"IEEE Robotics and Automation Society."})," - Professional organization with extensive resources, conferences, and publications on robotics research."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/",children:"ROS Documentation and Tutorials."})," - Official ROS 2 documentation and learning resources."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://docs.nvidia.com/isaac/",children:"NVIDIA Isaac Documentation."})," - Technical documentation for NVIDIA's Isaac robotics platform."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation Environments"}),": Links to Gazebo, Isaac Sim, and PyBullet documentation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Open Source Libraries"}),": ROS 2, MoveIt, OpenRAVE, and other essential robotics libraries"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Hardware Suppliers"}),": Recommended vendors for robotics components and sensors"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Community Forums"}),": ROS Answers, NVIDIA Developer Forums, and robotics communities"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Research Datasets"}),": Common datasets for robotics perception and manipulation tasks"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}}}]);