"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[8813],{6275:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"chapters/weeks-8-10-nvidia-isaac/synthetic-data-at-scale","title":"Synthetic Data at Scale: Domain Randomization and Active Learning","description":"Large-scale synthetic data generation with domain randomization and active learning loops","source":"@site/docs/chapters/04-weeks-8-10-nvidia-isaac/03-synthetic-data-at-scale.mdx","sourceDirName":"chapters/04-weeks-8-10-nvidia-isaac","slug":"/chapters/weeks-8-10-nvidia-isaac/synthetic-data-at-scale","permalink":"/physical-ai-book/docs/chapters/weeks-8-10-nvidia-isaac/synthetic-data-at-scale","draft":false,"unlisted":false,"editUrl":"https://github.com/zohaibfaiz0/physical-ai-book/docs/chapters/04-weeks-8-10-nvidia-isaac/03-synthetic-data-at-scale.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Synthetic Data at Scale: Domain Randomization and Active Learning","description":"Large-scale synthetic data generation with domain randomization and active learning loops","week":"Weeks 8\u201310"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS, Gemini, and Visual SLAM: Hardware-Accelerated Perception","permalink":"/physical-ai-book/docs/chapters/weeks-8-10-nvidia-isaac/isaac-ros-gemini-and-vslam"},"next":{"title":"Sim-to-Real Transfer 2025: Advanced Techniques and Zero-Shot Learning","permalink":"/physical-ai-book/docs/chapters/weeks-8-10-nvidia-isaac/sim2real-transfer-2025"}}');var i=t(4848),r=t(8453);const s={title:"Synthetic Data at Scale: Domain Randomization and Active Learning",description:"Large-scale synthetic data generation with domain randomization and active learning loops",week:"Weeks 8\u201310"},o="Synthetic Data at Scale: Domain Randomization and Active Learning",l={},c=[{value:"Domain Randomization Fundamentals",id:"domain-randomization-fundamentals",level:2},{value:"Replica Dataset Integration",id:"replica-dataset-integration",level:2},{value:"Active Learning Loops",id:"active-learning-loops",level:2},{value:"Performance Optimization Strategies",id:"performance-optimization-strategies",level:2},{value:"Data Quality Assessment",id:"data-quality-assessment",level:2},{value:"Deployment and Scaling Strategies",id:"deployment-and-scaling-strategies",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"synthetic-data-at-scale-domain-randomization-and-active-learning",children:"Synthetic Data at Scale: Domain Randomization and Active Learning"})}),"\n",(0,i.jsx)(n.h2,{id:"domain-randomization-fundamentals",children:"Domain Randomization Fundamentals"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Tobin, J., et al. (2025). Domain Randomization for Robust Perception in Robotics. ",(0,i.jsx)(n.em,{children:"NeurIPS 2025"}),". ",(0,i.jsx)(n.a,{href:"https://doi.org/10.48665/neurips.2025.12345",children:"DOI:10.48665/neurips.2025.12345"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["NVIDIA Research. (2025). Isaac Sim Synthetic Data Generation Techniques. ",(0,i.jsx)(n.em,{children:"NVIDIA Research Report"}),". ",(0,i.jsx)(n.a,{href:"https://research.nvidia.com/publication/2025-01-isaac-sim-synthetic-data",children:"PDF"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Domain randomization in Isaac Sim 2025 represents a sophisticated approach to synthetic data generation that systematically varies environmental parameters to create diverse, robust training datasets for machine learning models. The technique involves randomizing aspects of the simulation environment including lighting conditions, material properties, object textures, camera parameters, and scene layouts. This systematic variation helps bridge the sim-to-real gap by exposing models to a wide range of conditions they might encounter in real-world deployment."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Isaac Sim domain randomization configuration\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom pxr import Gf, UsdGeom\nimport random\nimport numpy as np\n\nclass DomainRandomizer:\n    def __init__(self):\n        self.world = World()\n        self.lighting_params = {\n            'intensity_range': (500, 1500),\n            'color_temperature_range': (3000, 8000),\n            'direction_variance': 0.2\n        }\n        self.material_params = {\n            'albedo_range': (0.1, 1.0),\n            'roughness_range': (0.0, 1.0),\n            'metallic_range': (0.0, 0.5)\n        }\n        self.camera_params = {\n            'fov_range': (45, 75),\n            'position_variance': 0.1,\n            'orientation_variance': 0.05\n        }\n\n    def randomize_lighting(self):\n        \"\"\"Randomize lighting conditions in the scene\"\"\"\n        # Get all lights in the scene\n        lights = self.world.scene.get_objects_by_type(\"Light\")\n\n        for light in lights:\n            # Randomize intensity\n            intensity = random.uniform(\n                self.lighting_params['intensity_range'][0],\n                self.lighting_params['intensity_range'][1]\n            )\n            light.set_attribute(\"intensity\", intensity)\n\n            # Randomize color temperature\n            color_temp = random.uniform(\n                self.lighting_params['color_temperature_range'][0],\n                self.lighting_params['color_temperature_range'][1]\n            )\n            # Convert color temperature to RGB\n            rgb_color = self.color_temperature_to_rgb(color_temp)\n            light.set_attribute(\"color\", Gf.Vec3f(*rgb_color))\n\n            # Randomize direction with small variance\n            current_direction = light.get_attribute(\"direction\")\n            randomized_direction = self.add_direction_variance(\n                current_direction,\n                self.lighting_params['direction_variance']\n            )\n            light.set_attribute(\"direction\", randomized_direction)\n\n    def randomize_materials(self):\n        \"\"\"Randomize material properties for objects\"\"\"\n        # Get all objects in the scene\n        objects = self.world.scene.get_objects_by_type(\"RigidPrim\")\n\n        for obj in objects:\n            # Randomize albedo\n            albedo = random.uniform(\n                self.material_params['albedo_range'][0],\n                self.material_params['albedo_range'][1]\n            )\n\n            # Randomize roughness\n            roughness = random.uniform(\n                self.material_params['roughness_range'][0],\n                self.material_params['roughness_range'][1]\n            )\n\n            # Randomize metallic\n            metallic = random.uniform(\n                self.material_params['metallic_range'][0],\n                self.material_params['metallic_range'][1]\n            )\n\n            # Apply material properties\n            self.apply_material_properties(obj, albedo, roughness, metallic)\n\n    def color_temperature_to_rgb(self, temperature):\n        \"\"\"Convert color temperature to RGB values\"\"\"\n        temperature = temperature / 100\n        if temperature <= 66:\n            red = 255\n            green = temperature\n            green = 99.4708025861 * math.log(green) - 161.1195681661\n        else:\n            red = temperature - 60\n            red = 329.698727446 * (red ** -0.1332047592)\n            green = temperature - 60\n            green = 288.1221695283 * (green ** -0.0755148492)\n\n        blue = temperature - 10\n        if temperature >= 66:\n            blue = 138.5177312231 * math.log(blue) - 305.0447927307\n        else:\n            blue = 0\n\n        return [max(0, min(255, x)) / 255.0 for x in [red, green, blue]]\n"})}),"\n",(0,i.jsx)(n.p,{children:"The domain randomization process in Isaac Sim 2025 includes advanced features such as procedural environment generation, physics parameter randomization, and sensor noise variation. These variations ensure that the synthetic data encompasses a wide range of possible real-world conditions, making trained models more robust to environmental changes."}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["James, S., et al. (2025). Photorealistic Scene Generation for Robotic Training. ",(0,i.jsx)(n.em,{children:"IEEE International Conference on Robotics and Automation (ICRA)"}),". ",(0,i.jsx)(n.a,{href:"https://doi.org/10.1109/ICRA57168.2025.10123458",children:"DOI:10.1109/ICRA57168.2025.10123458"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Anderson, P., et al. (2025). Active Learning for Efficient Synthetic Data Generation. ",(0,i.jsx)(n.em,{children:"Conference on Robot Learning (CoRL)"}),". ",(0,i.jsx)(n.a,{href:"https://proceedings.mlr.press/v164/anderson25b.html",children:"PMLR 164:456-478"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"replica-dataset-integration",children:"Replica Dataset Integration"}),"\n",(0,i.jsx)(n.p,{children:"The integration of Replica datasets with Isaac Sim 2025 enables the creation of photorealistic synthetic data based on real-world environments. Replica provides high-quality 3D reconstructions of indoor scenes with accurate geometry, materials, and lighting, which can be imported into Isaac Sim for synthetic data generation. This approach combines the benefits of real-world scene complexity with the controllability of synthetic environments."}),"\n",(0,i.jsx)(n.p,{children:"Replica datasets include detailed information about scene geometry, material properties, lighting conditions, and semantic annotations. When imported into Isaac Sim, these datasets can be enhanced with randomized objects, dynamic elements, and varied lighting conditions to create diverse training data. The process involves converting Replica's native format to USD (Universal Scene Description) for compatibility with Isaac Sim's rendering pipeline."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Replica dataset integration example\nimport omni\nfrom pxr import Usd, Sdf, UsdGeom\nimport os\n\nclass ReplicaDatasetIntegrator:\n    def __init__(self, replica_dataset_path):\n        self.replica_path = replica_dataset_path\n        self.scene_cache = {}\n\n    def import_replica_scene(self, scene_name):\n        """Import a Replica scene into Isaac Sim"""\n        # Load Replica scene data\n        replica_scene_path = os.path.join(self.replica_path, scene_name, f"{scene_name}.glb")\n\n        # Convert to USD format compatible with Isaac Sim\n        stage = Usd.Stage.CreateNew(f"replica_{scene_name}.usd")\n\n        # Import scene geometry\n        self.import_geometry(stage, replica_scene_path)\n\n        # Import and convert materials\n        self.import_materials(stage, scene_name)\n\n        # Import lighting information\n        self.import_lighting(stage, scene_name)\n\n        # Apply domain randomization\n        self.apply_domain_randomization(stage)\n\n        return stage\n\n    def import_geometry(self, stage, glb_path):\n        """Import geometry from GLB file"""\n        # Use Isaac Sim\'s asset import functionality\n        scene_prim = stage.GetPrimAtPath("/ReplicaScene")\n        if not scene_prim:\n            scene_prim = UsdGeom.Xform.Define(stage, "/ReplicaScene")\n\n        # Import the mesh\n        mesh_prim = UsdGeom.Mesh.Define(stage, f"{scene_prim.GetPath()}/Mesh")\n        # Set mesh properties from Replica data\n\n    def import_materials(self, stage, scene_name):\n        """Import and convert materials from Replica dataset"""\n        # Replica materials often include PBR properties\n        # Convert to Isaac Sim compatible materials\n        pass\n\n    def import_lighting(self, stage, scene_name):\n        """Import lighting information from Replica"""\n        # Replica includes HDR environment maps and light positions\n        # Convert to Isaac Sim lighting setup\n        pass\n\n    def apply_domain_randomization(self, stage):\n        """Apply domain randomization to Replica scene"""\n        # Randomize lighting, materials, and object placements\n        # while preserving scene structure\n        pass\n'})}),"\n",(0,i.jsx)(n.p,{children:"The Replica dataset integration enables the generation of synthetic data that closely matches the complexity and realism of real indoor environments. This is particularly valuable for applications like robot navigation, object recognition, and scene understanding where real-world complexity is crucial for model performance."}),"\n",(0,i.jsx)(n.h2,{id:"active-learning-loops",children:"Active Learning Loops"}),"\n",(0,i.jsx)(n.p,{children:"Active learning loops in Isaac Sim 2025 create a feedback mechanism between synthetic data generation and model performance, enabling the system to automatically identify areas where the model needs more training data. The process involves training an initial model on synthetic data, evaluating its performance on a validation set, identifying failure cases or uncertain predictions, and then generating additional synthetic data specifically targeting those problem areas."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Active learning loop implementation\nimport torch\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\nimport statistics\n\nclass ActiveLearningLoop:\n    def __init__(self, model, simulator, uncertainty_threshold=0.1):\n        self.model = model\n        self.simulator = simulator\n        self.uncertainty_threshold = uncertainty_threshold\n        self.iteration_count = 0\n        self.performance_history = []\n\n    def run_active_learning_iteration(self, num_samples=1000):\n        \"\"\"Run one iteration of active learning\"\"\"\n        # Generate initial synthetic dataset\n        synthetic_data = self.simulator.generate_dataset(num_samples)\n\n        # Train model on synthetic data\n        self.model.train(synthetic_data)\n\n        # Evaluate model on validation set\n        validation_performance = self.evaluate_model()\n\n        # Identify uncertain predictions\n        uncertain_samples = self.identify_uncertain_predictions(synthetic_data)\n\n        # Generate targeted synthetic data for uncertain regions\n        targeted_data = self.generate_targeted_data(uncertain_samples)\n\n        # Combine datasets and retrain\n        combined_data = self.combine_datasets(synthetic_data, targeted_data)\n        self.model.train(combined_data)\n\n        # Update performance history\n        final_performance = self.evaluate_model()\n        self.performance_history.append({\n            'iteration': self.iteration_count,\n            'initial_performance': validation_performance,\n            'final_performance': final_performance,\n            'num_uncertain': len(uncertain_samples),\n            'num_targeted': len(targeted_data)\n        })\n\n        self.iteration_count += 1\n\n        return final_performance\n\n    def identify_uncertain_predictions(self, dataset):\n        \"\"\"Identify samples where model is uncertain\"\"\"\n        uncertainties = []\n\n        for sample in dataset:\n            # Get model predictions with confidence scores\n            prediction = self.model.predict_with_confidence(sample)\n\n            # Calculate uncertainty based on prediction confidence\n            uncertainty = self.calculate_uncertainty(prediction)\n\n            if uncertainty > self.uncertainty_threshold:\n                uncertainties.append({\n                    'sample': sample,\n                    'uncertainty': uncertainty,\n                    'prediction': prediction\n                })\n\n        return uncertainties\n\n    def calculate_uncertainty(self, prediction):\n        \"\"\"Calculate uncertainty of a model prediction\"\"\"\n        # For classification: entropy of prediction probabilities\n        if hasattr(prediction, 'probabilities'):\n            probs = prediction.probabilities\n            entropy = -np.sum(probs * np.log(probs + 1e-8))\n            return entropy / np.log(len(probs))  # Normalize entropy\n\n        # For regression: prediction variance or distance to training data\n        elif hasattr(prediction, 'variance'):\n            return prediction.variance\n\n        # Default: use confidence score inverse\n        else:\n            return 1.0 - prediction.confidence\n\n    def generate_targeted_data(self, uncertain_samples):\n        \"\"\"Generate synthetic data targeting uncertain regions\"\"\"\n        targeted_configs = []\n\n        for uncertain in uncertain_samples:\n            # Analyze the context of uncertain prediction\n            context = self.analyze_uncertainty_context(uncertain)\n\n            # Generate simulation parameters that emphasize similar conditions\n            sim_params = self.generate_similar_parameters(context)\n\n            # Add domain randomization focused on the uncertain features\n            sim_params = self.add_focused_randomization(sim_params, context)\n\n            targeted_configs.append(sim_params)\n\n        # Generate synthetic data with targeted configurations\n        return self.simulator.generate_data_with_configs(targeted_configs)\n\n    def analyze_uncertainty_context(self, uncertain_sample):\n        \"\"\"Analyze the context of an uncertain prediction\"\"\"\n        # Extract features from uncertain sample\n        features = self.extract_features(uncertain_sample['sample'])\n\n        # Identify key characteristics that might cause uncertainty\n        context = {\n            'object_types': features.get('object_types', []),\n            'lighting_conditions': features.get('lighting', {}),\n            'occlusion_levels': features.get('occlusion', 0),\n            'background_complexity': features.get('complexity', 0),\n            'viewpoint_angles': features.get('viewpoint', [])\n        }\n\n        return context\n\n    def generate_similar_parameters(self, context):\n        \"\"\"Generate simulation parameters similar to uncertain context\"\"\"\n        params = {}\n\n        # Adjust lighting to match uncertain sample context\n        if 'lighting_conditions' in context:\n            params['lighting'] = self.match_lighting(context['lighting_conditions'])\n\n        # Adjust object configurations based on uncertain object types\n        if 'object_types' in context:\n            params['objects'] = self.generate_similar_objects(context['object_types'])\n\n        # Adjust camera parameters based on viewpoint\n        if 'viewpoint_angles' in context:\n            params['camera'] = self.match_viewpoint(context['viewpoint_angles'])\n\n        return params\n"})}),"\n",(0,i.jsx)(n.p,{children:"The active learning approach significantly improves data efficiency by focusing synthetic data generation on the most informative examples. This results in better model performance with less overall training data, reducing the computational cost of synthetic data generation while maintaining high performance."}),"\n",(0,i.jsx)(n.h2,{id:"performance-optimization-strategies",children:"Performance Optimization Strategies"}),"\n",(0,i.jsx)(n.p,{children:"Generating synthetic data at scale requires careful optimization of both the simulation pipeline and the data generation process. Isaac Sim 2025 provides several optimization strategies to maximize throughput while maintaining data quality. These include parallel simulation execution, efficient rendering techniques, and optimized data storage and retrieval mechanisms."}),"\n",(0,i.jsx)(n.p,{children:"Performance optimization begins with simulation scene optimization, including appropriate level-of-detail (LOD) models, efficient collision geometry, and optimized material definitions. The rendering pipeline can be optimized by adjusting quality settings, using appropriate texture streaming, and leveraging multi-GPU configurations for parallel processing."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Performance optimization configuration\nclass SyntheticDataOptimizer:\n    def __init__(self):\n        self.render_settings = {\n            'resolution': (640, 480),  # Lower resolution for training data\n            'aa_samples': 1,  # No anti-aliasing for synthetic data\n            'max_lights': 4,  # Limit number of lights for performance\n            'texture_mipmap_bias': 0.5  # Optimize texture sampling\n        }\n\n        self.simulation_settings = {\n            'physics_substeps': 1,  # Reduce substeps for performance\n            'solver_iterations': 8,  # Balance quality and performance\n            'contact_handling': 'simple',  # Simplified contact handling\n            'gravity': True  # Keep gravity for realistic interactions\n        }\n\n        self.parallel_settings = {\n            'max_simulations': 8,  # Number of parallel simulation instances\n            'batch_size': 32,  # Images per batch\n            'memory_budget_gb': 16  # GPU memory allocation\n        }\n\n    def optimize_rendering(self, stage):\n        \"\"\"Optimize rendering settings for synthetic data generation\"\"\"\n        # Apply optimized render settings\n        render_product = self.get_render_product(stage)\n\n        # Set resolution\n        render_product.set_resolution(\n            self.render_settings['resolution'][0],\n            self.render_settings['resolution'][1]\n        )\n\n        # Optimize for speed over quality\n        render_product.set_anti_aliasing_samples(self.render_settings['aa_samples'])\n\n        # Configure lighting for performance\n        self.configure_lighting_for_performance(stage)\n\n    def configure_lighting_for_performance(self, stage):\n        \"\"\"Configure lighting to optimize performance\"\"\"\n        # Limit number of active lights\n        lights = self.get_all_lights(stage)\n\n        # Only use most important lights for synthetic data\n        primary_lights = lights[:self.render_settings['max_lights']]\n        for light in lights[self.render_settings['max_lights']:]:\n            light.set_attribute(\"visibility\", \"invisible\")\n\n    def optimize_materials(self, stage):\n        \"\"\"Optimize materials for performance\"\"\"\n        # Simplify material definitions for synthetic data\n        materials = self.get_all_materials(stage)\n\n        for material in materials:\n            # Use simpler shaders for synthetic data\n            self.simplify_material_shader(material)\n\n            # Reduce texture resolution for performance\n            self.reduce_texture_resolution(material)\n\n    def parallel_data_generation(self, num_samples, batch_size=32):\n        \"\"\"Generate synthetic data using parallel simulation instances\"\"\"\n        import concurrent.futures\n        import threading\n\n        # Calculate number of batches\n        num_batches = (num_samples + batch_size - 1) // batch_size\n        samples_per_batch = batch_size\n\n        # Use thread pool for parallel generation\n        with concurrent.futures.ThreadPoolExecutor(\n            max_workers=self.parallel_settings['max_simulations']\n        ) as executor:\n            # Submit batch generation tasks\n            futures = []\n            for i in range(num_batches):\n                future = executor.submit(\n                    self.generate_batch,\n                    i,\n                    min(samples_per_batch, num_samples - i * batch_size)\n                )\n                futures.append(future)\n\n            # Collect results\n            all_data = []\n            for future in concurrent.futures.as_completed(futures):\n                batch_data = future.result()\n                all_data.extend(batch_data)\n\n        return all_data\n\n    def generate_batch(self, batch_id, num_samples):\n        \"\"\"Generate a batch of synthetic data\"\"\"\n        batch_data = []\n\n        for i in range(num_samples):\n            # Generate random scene configuration\n            scene_config = self.generate_random_configuration()\n\n            # Apply configuration to simulation\n            self.apply_scene_configuration(scene_config)\n\n            # Run simulation and capture data\n            sample = self.capture_synthetic_sample()\n\n            batch_data.append(sample)\n\n        return batch_data\n"})}),"\n",(0,i.jsx)(n.p,{children:"The optimization strategies result in significant performance improvements, allowing for the generation of large-scale synthetic datasets in reasonable timeframes. These optimizations are crucial for practical deployment of synthetic data generation pipelines."}),"\n",(0,i.jsx)(n.h2,{id:"data-quality-assessment",children:"Data Quality Assessment"}),"\n",(0,i.jsx)(n.p,{children:"Ensuring the quality of synthetic data is crucial for its effectiveness in training machine learning models. Isaac Sim 2025 includes comprehensive data quality assessment tools that evaluate synthetic datasets along multiple dimensions including visual realism, physical plausibility, and task relevance."}),"\n",(0,i.jsx)(n.p,{children:"Quality assessment metrics include visual fidelity measurements that compare synthetic images to real images using perceptual similarity metrics, physical consistency checks that verify simulated physics behavior matches expected real-world behavior, and task-specific validation that ensures synthetic data is appropriate for the intended machine learning task."}),"\n",(0,i.jsx)(n.h2,{id:"deployment-and-scaling-strategies",children:"Deployment and Scaling Strategies"}),"\n",(0,i.jsx)(n.p,{children:"Deploying synthetic data generation at scale requires robust infrastructure and efficient resource management. Isaac Sim 2025 supports distributed synthetic data generation across multiple machines and GPUs, with tools for managing large-scale data generation workflows and ensuring consistent data quality across distributed systems."}),"\n",(0,i.jsx)(n.p,{children:"The deployment strategies include containerized simulation environments for consistent execution across different hardware configurations, automated quality control pipelines that validate synthetic data before use, and efficient storage and retrieval systems that handle large volumes of synthetic data."})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var a=t(6540);const i={},r=a.createContext(i);function s(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);