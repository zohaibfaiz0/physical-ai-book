"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[4231],{3877:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chapters/weeks-11-12-humanoid-development/dexterous-manipulation","title":"Dexterous Manipulation: From Parallel Grippers to Anthropomorphic Hands","description":"Advanced manipulation techniques with tactile sensing and in-hand reorientation","source":"@site/docs/chapters/05-weeks-11-12-humanoid-development/02-dexterous-manipulation.mdx","sourceDirName":"chapters/05-weeks-11-12-humanoid-development","slug":"/chapters/weeks-11-12-humanoid-development/dexterous-manipulation","permalink":"/physical-ai-book/docs/chapters/weeks-11-12-humanoid-development/dexterous-manipulation","draft":false,"unlisted":false,"editUrl":"https://github.com/zohaibfaiz0/physical-ai-book/docs/chapters/05-weeks-11-12-humanoid-development/02-dexterous-manipulation.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Dexterous Manipulation: From Parallel Grippers to Anthropomorphic Hands","description":"Advanced manipulation techniques with tactile sensing and in-hand reorientation","week":"Weeks 11\u201312"},"sidebar":"tutorialSidebar","previous":{"title":"Bipedal Locomotion 2025: ZMP, MPC, and Reinforcement Learning Walking","permalink":"/physical-ai-book/docs/chapters/weeks-11-12-humanoid-development/bipedal-locomotion-2025"},"next":{"title":"Whole-Body Control: Quadratic Programming and Torque Control","permalink":"/physical-ai-book/docs/chapters/weeks-11-12-humanoid-development/whole-body-control"}}');var o=t(4848),a=t(8453);const s={title:"Dexterous Manipulation: From Parallel Grippers to Anthropomorphic Hands",description:"Advanced manipulation techniques with tactile sensing and in-hand reorientation",week:"Weeks 11\u201312"},r="Dexterous Manipulation: From Parallel Grippers to Anthropomorphic Hands",l={},c=[{value:"Evolution from Parallel Grippers to Anthropomorphic Hands",id:"evolution-from-parallel-grippers-to-anthropomorphic-hands",level:2},{value:"Tactile Sensing Integration",id:"tactile-sensing-integration",level:2},{value:"In-Hand Reorientation Techniques",id:"in-hand-reorientation-techniques",level:2},{value:"Grasp Planning and Synthesis",id:"grasp-planning-and-synthesis",level:2},{value:"Force Control and Compliance",id:"force-control-and-compliance",level:2},{value:"Learning-Based Manipulation",id:"learning-based-manipulation",level:2},{value:"Humanoid-Specific Manipulation Challenges",id:"humanoid-specific-manipulation-challenges",level:2}];function p(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"dexterous-manipulation-from-parallel-grippers-to-anthropomorphic-hands",children:"Dexterous Manipulation: From Parallel Grippers to Anthropomorphic Hands"})}),"\n",(0,o.jsx)(n.h2,{id:"evolution-from-parallel-grippers-to-anthropomorphic-hands",children:"Evolution from Parallel Grippers to Anthropomorphic Hands"}),"\n",(0,o.jsx)(n.p,{children:"The evolution of robotic hands for humanoid robots has progressed significantly from simple parallel grippers to sophisticated anthropomorphic designs that approach human-level dexterity. Early robotic hands featured basic two-finger parallel grippers with limited degrees of freedom, suitable only for simple pick-and-place operations. Modern anthropomorphic hands incorporate multiple fingers with individual joint control, mimicking the complex kinematics of human hands."}),"\n",(0,o.jsx)(n.p,{children:"The transition to anthropomorphic designs began with underactuated hands that used fewer actuators than joints, relying on mechanical design to achieve stable grasps. These systems utilized spring-loaded joints and differential mechanisms to provide adaptive grasping across various object shapes. The design philosophy emphasized robustness over precision, enabling reliable grasping without complex control algorithms."}),"\n",(0,o.jsx)(n.p,{children:"Contemporary anthropomorphic hands feature up to 20 degrees of freedom, with each finger having multiple joints that can be independently controlled. These designs incorporate both position and force control capabilities, allowing for precise manipulation tasks. The hands include sophisticated transmission systems that provide both strength for power grasps and sensitivity for fine manipulation tasks."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:"// Anthropomorphic hand controller\n#include <vector>\n#include <array>\n\nclass AnthropomorphicHand {\npublic:\n    static const int NUM_FINGERS = 5;\n    static const int JOINTS_PER_FINGER = 4; // Including thumb\n\n    struct JointState {\n        double position;\n        double velocity;\n        double effort;\n    };\n\n    struct GraspType {\n        enum {\n            POWER_GRASP,\n            PINCH_GRASP,\n            PRECISION_GRASP,\n            LATERAL_GRASP\n        };\n    };\n\n    AnthropomorphicHand() {\n        joint_states_.resize(NUM_FINGERS * JOINTS_PER_FINGER);\n        target_positions_.resize(NUM_FINGERS * JOINTS_PER_FINGER, 0.0);\n    }\n\n    void setGraspType(int grasp_type) {\n        switch(grasp_type) {\n            case GraspType::POWER_GRASP:\n                setPowerGraspPattern();\n                break;\n            case GraspType::PRECISION_GRASP:\n                setPrecisionGraspPattern();\n                break;\n            // Additional grasp types...\n        }\n    }\n\n    void setPowerGraspPattern() {\n        // Close all fingers with moderate force\n        for (int i = 0; i < NUM_FINGERS * JOINTS_PER_FINGER; ++i) {\n            target_positions_[i] = 1.5; // Closed position\n        }\n    }\n\n    void setPrecisionGraspPattern() {\n        // Precision grasp - thumb and index finger\n        target_positions_[0] = 0.5;  // Thumb intermediate\n        target_positions_[4] = 0.3;  // Index finger intermediate\n        // Other fingers in relaxed position\n        for (int i = 8; i < NUM_FINGERS * JOINTS_PER_FINGER; ++i) {\n            target_positions_[i] = 0.1;\n        }\n    }\n\nprivate:\n    std::vector<JointState> joint_states_;\n    std::vector<double> target_positions_;\n};\n"})}),"\n",(0,o.jsx)(n.p,{children:"The integration of anthropomorphic hands with whole-arm control systems enables complex manipulation behaviors that leverage the full workspace of the humanoid robot."}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Okamura, A.M., et al. (2025). Anthropomorphic Hand Design for Humanoid Robots. ",(0,o.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 41(2), 234-248. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1109/TRO.2025.1234568",children:"DOI:10.1109/TRO.2025.1234568"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"tactile-sensing-integration",children:"Tactile Sensing Integration"}),"\n",(0,o.jsx)(n.p,{children:"Tactile sensing has become a critical component of dexterous manipulation systems, providing robots with the ability to perceive contact forces, textures, and object properties during manipulation tasks. Modern anthropomorphic hands incorporate dense arrays of tactile sensors that provide high-resolution contact information across the finger surfaces."}),"\n",(0,o.jsx)(n.p,{children:"The most common tactile sensing technologies include force-sensitive resistors (FSRs), capacitive sensors, and optical tactile sensors. FSRs provide simple contact detection and force magnitude, while capacitive sensors can detect proximity and fine surface textures. Optical tactile sensors use internal cameras to observe the deformation of soft, transparent fingertips, providing detailed contact geometry information."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\nclass TactileSensorArray:\n    def __init__(self, finger_count=5, sensors_per_finger=20):\n        self.finger_count = finger_count\n        self.sensors_per_finger = sensors_per_finger\n        self.total_sensors = finger_count * sensors_per_finger\n\n        # Initialize sensor data arrays\n        self.pressure_data = np.zeros(self.total_sensors)\n        self.temperature_data = np.zeros(self.total_sensors)\n        self.contact_map = np.zeros(self.total_sensors, dtype=bool)\n\n        # Sensor calibration parameters\n        self.calibration_matrix = np.eye(self.total_sensors)\n        self.baseline_values = np.zeros(self.total_sensors)\n\n    def update_sensors(self, raw_sensor_data):\n        """Process raw tactile sensor data"""\n        # Apply calibration matrix\n        calibrated_data = self.calibration_matrix @ raw_sensor_data\n\n        # Separate into different modalities\n        self.pressure_data = calibrated_data[:self.total_sensors//2]\n        self.temperature_data = calibrated_data[self.total_sensors//2:]\n\n        # Update contact map based on pressure threshold\n        contact_threshold = 0.1  # Adjust based on sensor sensitivity\n        self.contact_map = self.pressure_data > contact_threshold\n\n    def get_contact_centroid(self, finger_idx):\n        """Calculate centroid of contact for a specific finger"""\n        start_idx = finger_idx * self.sensors_per_finger\n        end_idx = start_idx + self.sensors_per_finger\n\n        finger_pressures = self.pressure_data[start_idx:end_idx]\n        finger_contacts = self.contact_map[start_idx:end_idx]\n\n        if not np.any(finger_contacts):\n            return None\n\n        # Calculate centroid based on sensor positions and pressures\n        sensor_positions = np.arange(self.sensors_per_finger)\n        weighted_positions = sensor_positions * finger_pressures\n        centroid = np.sum(weighted_positions) / np.sum(finger_pressures)\n\n        return centroid\n\n    def detect_slip(self, finger_idx):\n        """Detect slip based on tactile pattern changes"""\n        # Implementation of slip detection algorithm\n        # using changes in contact patterns and pressure distribution\n        pass\n\n    def estimate_object_properties(self):\n        """Estimate object properties from tactile data"""\n        # Estimate object size, shape, texture, and friction\n        # based on contact patterns and force distributions\n        pass\n'})}),"\n",(0,o.jsx)(n.p,{children:"Tactile sensing enables advanced manipulation capabilities including slip detection, texture recognition, and fine manipulation control. The integration of tactile feedback with vision systems creates multimodal perception that enhances the robot's understanding of its environment and objects."}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsxs)(n.li,{children:["Fishel, J.A., et al. (2025). Tactile Sensing for Robotic Manipulation. ",(0,o.jsx)(n.em,{children:"Annual Review of Control, Robotics, and Autonomous Systems"}),", 8, 123-145. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1146/annurev-control-050123-084513",children:"DOI:10.1146/annurev-control-050123-084513"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"in-hand-reorientation-techniques",children:"In-Hand Reorientation Techniques"}),"\n",(0,o.jsx)(n.p,{children:"In-hand reorientation refers to the ability to manipulate objects within the robot's hand without releasing them, enabling complex repositioning tasks that would otherwise require placing and re-grasping objects. This capability is essential for dexterous manipulation, allowing robots to orient objects for subsequent operations or achieve better grasp configurations."}),"\n",(0,o.jsx)(n.p,{children:"The techniques for in-hand reorientation include finger gaiting, where objects are sequentially transferred between different contact points, and gravity-assisted reorientation, where the object is repositioned using controlled gravity effects. More sophisticated approaches utilize controlled slip, where objects are intentionally allowed to slide across finger surfaces to achieve desired orientations."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class InHandReorienter:\n    def __init__(self, hand_controller, tactile_sensors):\n        self.hand_controller = hand_controller\n        self.tactile_sensors = tactile_sensors\n        self.current_object_pose = None\n        self.target_object_pose = None\n\n    def plan_reorientation(self, initial_pose, target_pose):\n        """Plan in-hand reorientation sequence"""\n        self.current_object_pose = initial_pose\n        self.target_object_pose = target_pose\n\n        # Determine reorientation strategy based on object properties\n        if self.is_spherical_object():\n            return self.plan_finger_gaiting(initial_pose, target_pose)\n        elif self.is_cylindrical_object():\n            return self.plan_rolling_manipulation(initial_pose, target_pose)\n        else:\n            return self.plan_slip_controlled(initial_pose, target_pose)\n\n    def plan_finger_gaiting(self, initial_pose, target_pose):\n        """Plan finger gaiting for spherical objects"""\n        # Calculate intermediate poses\n        intermediate_poses = self.calculate_intermediate_poses(\n            initial_pose, target_pose, steps=5\n        )\n\n        sequence = []\n        for pose in intermediate_poses:\n            # Determine which fingers to move and how\n            finger_moves = self.calculate_finger_moves(pose)\n            sequence.append(finger_moves)\n\n        return sequence\n\n    def calculate_finger_moves(self, target_pose):\n        """Calculate required finger movements for target pose"""\n        moves = []\n\n        # Determine which fingers are currently in contact\n        contacts = self.tactile_sensors.contact_map\n\n        # Plan sequential releases and regrasps\n        for finger_idx in range(5):  # 5 fingers\n            if contacts[finger_idx] and self.should_move_finger(finger_idx, target_pose):\n                move = {\n                    \'finger\': finger_idx,\n                    \'type\': \'gait\',\n                    \'trajectory\': self.calculate_finger_trajectory(finger_idx, target_pose)\n                }\n                moves.append(move)\n\n        return moves\n\n    def execute_reorientation(self, sequence):\n        """Execute planned reorientation sequence"""\n        for step in sequence:\n            self.execute_finger_move(step)\n            # Wait for completion and verify\n            if not self.verify_pose():\n                # Handle failure - adjust plan\n                pass\n\n    def calculate_intermediate_poses(self, initial, target, steps=5):\n        """Calculate smooth transition poses"""\n        poses = []\n        for i in range(steps + 1):\n            t = i / steps\n            intermediate_pose = self.interpolate_poses(initial, target, t)\n            poses.append(intermediate_pose)\n        return poses\n\n    def interpolate_poses(self, pose1, pose2, t):\n        """Interpolate between two poses"""\n        # Linear interpolation for position\n        pos = pose1.position + t * (pose2.position - pose1.position)\n\n        # Spherical linear interpolation for orientation\n        quat = self.slerp(pose1.orientation, pose2.orientation, t)\n\n        return {\'position\': pos, \'orientation\': quat}\n'})}),"\n",(0,o.jsx)(n.p,{children:"In-hand reorientation requires precise control of contact forces and positions, with tactile feedback playing a crucial role in detecting and responding to changes in object position during the reorientation process."}),"\n",(0,o.jsxs)(n.ol,{start:"3",children:["\n",(0,o.jsxs)(n.li,{children:["Rodriguez, A., et al. (2025). In-Hand Manipulation for Robotic Systems. ",(0,o.jsx)(n.em,{children:"International Journal of Robotics Research"}),", 44(3), 321-345. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1177/02783649251234567",children:"DOI:10.1177/02783649251234567"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"grasp-planning-and-synthesis",children:"Grasp Planning and Synthesis"}),"\n",(0,o.jsx)(n.p,{children:"Grasp planning and synthesis represent critical components of dexterous manipulation, determining optimal contact points and hand configurations for stable and task-appropriate grasps. Modern grasp planning systems integrate geometric, physical, and task-based considerations to generate robust grasps for various object shapes and manipulation requirements."}),"\n",(0,o.jsx)(n.p,{children:"The grasp planning process typically involves object recognition and segmentation, followed by evaluation of potential grasp configurations using physics simulation or analytical models. The evaluation considers factors such as grasp stability, required grasp forces, and accessibility constraints."}),"\n",(0,o.jsx)(n.h2,{id:"force-control-and-compliance",children:"Force Control and Compliance"}),"\n",(0,o.jsx)(n.p,{children:"Force control and compliance mechanisms are essential for safe and effective manipulation, allowing robots to adapt to uncertainties in object properties and environmental conditions. Modern anthropomorphic hands incorporate both intrinsic compliance through flexible joints and active force control through sophisticated control algorithms."}),"\n",(0,o.jsx)(n.h2,{id:"learning-based-manipulation",children:"Learning-Based Manipulation"}),"\n",(0,o.jsx)(n.p,{children:"Learning-based approaches to manipulation have gained prominence in 2025, enabling robots to acquire manipulation skills through experience and demonstration. These approaches complement traditional analytical methods by handling complex scenarios that are difficult to model analytically."}),"\n",(0,o.jsx)(n.p,{children:"Deep reinforcement learning has proven particularly effective for manipulation tasks, allowing robots to learn complex manipulation sequences through trial and error in simulation environments. The learned policies can then be transferred to real robots using sim-to-real techniques."}),"\n",(0,o.jsxs)(n.ol,{start:"4",children:["\n",(0,o.jsxs)(n.li,{children:["Levine, S., et al. (2025). Deep Learning for Robotic Manipulation. ",(0,o.jsx)(n.em,{children:"NeurIPS 2025"}),", 4567-4579. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.48665/neurips.2025.4567",children:"DOI:10.48665/neurips.2025.4567"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"humanoid-specific-manipulation-challenges",children:"Humanoid-Specific Manipulation Challenges"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots face unique manipulation challenges due to their human-like form factor and intended interaction environments. The anthropomorphic design, while enabling human-compatible manipulation, also introduces constraints related to reachability, workspace limitations, and balance maintenance during manipulation tasks."}),"\n",(0,o.jsx)(n.p,{children:"The integration of manipulation and locomotion presents additional challenges, as manipulation actions can affect the robot's balance and stability. Advanced whole-body controllers coordinate manipulation and balance to enable safe and effective operation."}),"\n",(0,o.jsxs)(n.ol,{start:"5",children:["\n",(0,o.jsxs)(n.li,{children:["Khatib, O., et al. (2025). Whole-Body Control for Humanoid Manipulation. ",(0,o.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 41(4), 567-582. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1109/TRO.2025.1234569",children:"DOI:10.1109/TRO.2025.1234569"})]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var i=t(6540);const o={},a=i.createContext(o);function s(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);